{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='C:\\\\Users\\\\Sara Latif Khan\\\\OneDrive\\\\Desktop\\\\FYP_\\\\Scene15\\\\15-Scene\\\\train',transform=transform)\n",
    "testset = torchvision.datasets.ImageFolder(root='C:\\\\Users\\\\Sara Latif Khan\\\\OneDrive\\\\Desktop\\\\FYP_\\\\Scene15\\\\15-Scene\\\\test', transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader:\n",
    "    print(images.size(), labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First thing we want to do when treating our network as a fixed feature classifier is to freeze the network, so all we\n",
    "#is to grab all the parameters and set the requires grad to false\n",
    "#First thing we want to with our network to fine tune is to freeze earlier layers of our model\n",
    "\n",
    "for param in model.parameters():  \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's train the fully connected head of our model, now let's take a look at our classiffier\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's train the fully connected head of our model, so the first thing we'll do is to unfreeze this\n",
    "for i in range(0,7):\n",
    "    model.classifier[i].requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have an option of removing the classifier, now I'm gonna start training from the last layer, so let's just replace\n",
    "# the fully connected layer with the/their 4096 features going to 1000 features\n",
    "# So I can access this section by accessing the sixth row of the classifier or by an index of 6, and I'll add my own fully connected classifier\n",
    "#that goes from a 4096 (features/ nodes) to 512 features/ nodes followed by a ReLU and dropout layer and then another fully connected\n",
    "#going from 512 nodes to 15 output nodes/classes (bcoz I do have 15 classes in my dataset), and this is going to be followed by a logsoftmax\n",
    "\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(4096,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512,15),\n",
    "    nn.LogSoftmax( dim = 1 )\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = model.to(device)  #Sending model to GPU\n",
    "optimizer = Adam(model.parameters())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training from the Fully Connected Section On Wards :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Training The Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(1/17) : Batch loss : 2.758256196975708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(2/17) : Batch loss : 2.3670828342437744\n",
      "Epoch(0/5 : Batch number(3/17) : Batch loss : 2.0973587036132812\n",
      "Epoch(0/5 : Batch number(4/17) : Batch loss : 1.9258208274841309\n",
      "Epoch(0/5 : Batch number(5/17) : Batch loss : 1.644967794418335\n",
      "Epoch(0/5 : Batch number(6/17) : Batch loss : 1.5352137088775635\n",
      "Epoch(0/5 : Batch number(7/17) : Batch loss : 1.3225994110107422\n",
      "Epoch(0/5 : Batch number(8/17) : Batch loss : 1.1585873365402222\n",
      "Epoch(0/5 : Batch number(9/17) : Batch loss : 0.8811482191085815\n",
      "Epoch(0/5 : Batch number(10/17) : Batch loss : 0.9643864035606384\n",
      "Epoch(0/5 : Batch number(11/17) : Batch loss : 0.7556966543197632\n",
      "Epoch(0/5 : Batch number(12/17) : Batch loss : 0.7535868287086487\n",
      "Epoch(0/5 : Batch number(13/17) : Batch loss : 0.5626626014709473\n",
      "Epoch(0/5 : Batch number(14/17) : Batch loss : 0.5292341113090515\n",
      "Epoch(0/5 : Batch number(15/17) : Batch loss : 0.7117160558700562\n",
      "Epoch(0/5 : Batch number(16/17) : Batch loss : 0.6523106098175049\n",
      "Epoch(0/5 : Batch number(17/17) : Batch loss : 0.6331368684768677\n",
      "Epoch(1/5 : Batch number(1/17) : Batch loss : 0.42377468943595886\n",
      "Epoch(1/5 : Batch number(2/17) : Batch loss : 0.4238568842411041\n",
      "Epoch(1/5 : Batch number(3/17) : Batch loss : 0.35089990496635437\n",
      "Epoch(1/5 : Batch number(4/17) : Batch loss : 0.3221866190433502\n",
      "Epoch(1/5 : Batch number(5/17) : Batch loss : 0.32170170545578003\n",
      "Epoch(1/5 : Batch number(6/17) : Batch loss : 0.35837069153785706\n",
      "Epoch(1/5 : Batch number(7/17) : Batch loss : 0.3612736165523529\n",
      "Epoch(1/5 : Batch number(8/17) : Batch loss : 0.4326012432575226\n",
      "Epoch(1/5 : Batch number(9/17) : Batch loss : 0.36701324582099915\n",
      "Epoch(1/5 : Batch number(10/17) : Batch loss : 0.45002108812332153\n",
      "Epoch(1/5 : Batch number(11/17) : Batch loss : 0.37225109338760376\n",
      "Epoch(1/5 : Batch number(12/17) : Batch loss : 0.3980635106563568\n",
      "Epoch(1/5 : Batch number(13/17) : Batch loss : 0.27433285117149353\n",
      "Epoch(1/5 : Batch number(14/17) : Batch loss : 0.2768181562423706\n",
      "Epoch(1/5 : Batch number(15/17) : Batch loss : 0.3442401587963104\n",
      "Epoch(1/5 : Batch number(16/17) : Batch loss : 0.26995256543159485\n",
      "Epoch(1/5 : Batch number(17/17) : Batch loss : 0.27746981382369995\n",
      "Epoch(2/5 : Batch number(1/17) : Batch loss : 0.4751754701137543\n",
      "Epoch(2/5 : Batch number(2/17) : Batch loss : 0.28022050857543945\n",
      "Epoch(2/5 : Batch number(3/17) : Batch loss : 0.24165718257427216\n",
      "Epoch(2/5 : Batch number(4/17) : Batch loss : 0.3737349212169647\n",
      "Epoch(2/5 : Batch number(5/17) : Batch loss : 0.18358764052391052\n",
      "Epoch(2/5 : Batch number(6/17) : Batch loss : 0.26711398363113403\n",
      "Epoch(2/5 : Batch number(7/17) : Batch loss : 0.3520473837852478\n",
      "Epoch(2/5 : Batch number(8/17) : Batch loss : 0.2270146608352661\n",
      "Epoch(2/5 : Batch number(9/17) : Batch loss : 0.4320654273033142\n",
      "Epoch(2/5 : Batch number(10/17) : Batch loss : 0.24402208626270294\n",
      "Epoch(2/5 : Batch number(11/17) : Batch loss : 0.4830232262611389\n",
      "Epoch(2/5 : Batch number(12/17) : Batch loss : 0.26059433817863464\n",
      "Epoch(2/5 : Batch number(13/17) : Batch loss : 0.2663021385669708\n",
      "Epoch(2/5 : Batch number(14/17) : Batch loss : 0.4252221882343292\n",
      "Epoch(2/5 : Batch number(15/17) : Batch loss : 0.37678611278533936\n",
      "Epoch(2/5 : Batch number(16/17) : Batch loss : 0.22623232007026672\n",
      "Epoch(2/5 : Batch number(17/17) : Batch loss : 0.41145119071006775\n",
      "Epoch(3/5 : Batch number(1/17) : Batch loss : 0.17484146356582642\n",
      "Epoch(3/5 : Batch number(2/17) : Batch loss : 0.09551438689231873\n",
      "Epoch(3/5 : Batch number(3/17) : Batch loss : 0.30427420139312744\n",
      "Epoch(3/5 : Batch number(4/17) : Batch loss : 0.4080490171909332\n",
      "Epoch(3/5 : Batch number(5/17) : Batch loss : 0.12490499764680862\n",
      "Epoch(3/5 : Batch number(6/17) : Batch loss : 0.3601173758506775\n",
      "Epoch(3/5 : Batch number(7/17) : Batch loss : 0.2584134042263031\n",
      "Epoch(3/5 : Batch number(8/17) : Batch loss : 0.3278332054615021\n",
      "Epoch(3/5 : Batch number(9/17) : Batch loss : 0.2748013436794281\n",
      "Epoch(3/5 : Batch number(10/17) : Batch loss : 0.27416935563087463\n",
      "Epoch(3/5 : Batch number(11/17) : Batch loss : 0.2324739396572113\n",
      "Epoch(3/5 : Batch number(12/17) : Batch loss : 0.2158319056034088\n",
      "Epoch(3/5 : Batch number(13/17) : Batch loss : 0.2655465006828308\n",
      "Epoch(3/5 : Batch number(14/17) : Batch loss : 0.3344252109527588\n",
      "Epoch(3/5 : Batch number(15/17) : Batch loss : 0.2719917893409729\n",
      "Epoch(3/5 : Batch number(16/17) : Batch loss : 0.1993809938430786\n",
      "Epoch(3/5 : Batch number(17/17) : Batch loss : 0.2129031866788864\n",
      "Epoch(4/5 : Batch number(1/17) : Batch loss : 0.12526598572731018\n",
      "Epoch(4/5 : Batch number(2/17) : Batch loss : 0.18283046782016754\n",
      "Epoch(4/5 : Batch number(3/17) : Batch loss : 0.25247475504875183\n",
      "Epoch(4/5 : Batch number(4/17) : Batch loss : 0.1618715077638626\n",
      "Epoch(4/5 : Batch number(5/17) : Batch loss : 0.21869927644729614\n",
      "Epoch(4/5 : Batch number(6/17) : Batch loss : 0.11390276998281479\n",
      "Epoch(4/5 : Batch number(7/17) : Batch loss : 0.2565329074859619\n",
      "Epoch(4/5 : Batch number(8/17) : Batch loss : 0.13834619522094727\n",
      "Epoch(4/5 : Batch number(9/17) : Batch loss : 0.21248950064182281\n",
      "Epoch(4/5 : Batch number(10/17) : Batch loss : 0.16391612589359283\n",
      "Epoch(4/5 : Batch number(11/17) : Batch loss : 0.2361270636320114\n",
      "Epoch(4/5 : Batch number(12/17) : Batch loss : 0.23422971367835999\n",
      "Epoch(4/5 : Batch number(13/17) : Batch loss : 0.1324280947446823\n",
      "Epoch(4/5 : Batch number(14/17) : Batch loss : 0.18704356253147125\n",
      "Epoch(4/5 : Batch number(15/17) : Batch loss : 0.191923126578331\n",
      "Epoch(4/5 : Batch number(16/17) : Batch loss : 0.2175988405942917\n",
      "Epoch(4/5 : Batch number(17/17) : Batch loss : 0.44513067603111267\n",
      "Training loss : 2.3888898018528435\n"
     ]
    }
   ],
   "source": [
    "# Training the model by Freezing everything except fully connected layers of the model\n",
    "\n",
    "dataset = 'C:\\\\Users\\\\Sara Latif Khan\\\\OneDrive\\\\Desktop\\\\FYP_\\\\Scene15\\\\15-Scene'\n",
    "model = model.to(device)\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "#Training Fixed Feature Extractor for 15 epochs\n",
    "num_epochs = 5\n",
    "batch_loss = 0\n",
    "cum_epoch_loss = 0 #cumulative loss for each batch\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cum_epoch_loss = 0\n",
    "  \n",
    "    for batch, (images, labels) in enumerate(trainloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        batch_loss += loss.item()\n",
    "        print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
    "        torch.save(model, dataset+'_model_'+str(e)+'.pt')\n",
    "    \n",
    "print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch (1 / 8)\n",
      "Batch (2 / 8)\n",
      "Batch (3 / 8)\n",
      "Batch (4 / 8)\n",
      "Batch (5 / 8)\n",
      "Batch (6 / 8)\n",
      "Batch (7 / 8)\n",
      "Batch (8 / 8)\n",
      "Accuracy of the model on 450 test images: 86.44444444444444% \n"
     ]
    }
   ],
   "source": [
    "model. to('cpu')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    #set_trace ()\n",
    "    for batch, (images,labels) in enumerate(testloader,1):\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output,1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        num_correct += (pred==labels).sum().item()\n",
    "        print(f'Batch ({batch} / {len(testloader)})')\n",
    "        \n",
    "        # to check the accuracy of model on 5 batches\n",
    "        # if batch == 5:\n",
    "            # break\n",
    "            \n",
    "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total }% ')            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreezing and training over the last CNN block onwards "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Vgg-16 last block is 3 Convolution layers followed by a Max-Pooling Layer, so when we look at model we are looking \n",
    "# at features from index 24-31, so we are going to train for 5 epochs\n",
    "\n",
    "for i in range(24,31):\n",
    "    model.features[i].requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(1/17) : Batch loss : 0.07259410619735718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(2/17) : Batch loss : 0.23101936280727386\n",
      "Epoch(0/5 : Batch number(3/17) : Batch loss : 0.06762712448835373\n",
      "Epoch(0/5 : Batch number(4/17) : Batch loss : 0.12869267165660858\n",
      "Epoch(0/5 : Batch number(5/17) : Batch loss : 0.3333587348461151\n",
      "Epoch(0/5 : Batch number(6/17) : Batch loss : 0.05554826930165291\n",
      "Epoch(0/5 : Batch number(7/17) : Batch loss : 0.20143495500087738\n",
      "Epoch(0/5 : Batch number(8/17) : Batch loss : 0.07500186562538147\n",
      "Epoch(0/5 : Batch number(9/17) : Batch loss : 0.09055822342634201\n",
      "Epoch(0/5 : Batch number(10/17) : Batch loss : 0.21043643355369568\n",
      "Epoch(0/5 : Batch number(11/17) : Batch loss : 0.1288479119539261\n",
      "Epoch(0/5 : Batch number(12/17) : Batch loss : 0.1466018259525299\n",
      "Epoch(0/5 : Batch number(13/17) : Batch loss : 0.08792094886302948\n",
      "Epoch(0/5 : Batch number(14/17) : Batch loss : 0.10559666901826859\n",
      "Epoch(0/5 : Batch number(15/17) : Batch loss : 0.16868874430656433\n",
      "Epoch(0/5 : Batch number(16/17) : Batch loss : 0.11264611035585403\n",
      "Epoch(0/5 : Batch number(17/17) : Batch loss : 0.19923445582389832\n",
      "Epoch(1/5 : Batch number(1/17) : Batch loss : 0.06391416490077972\n",
      "Epoch(1/5 : Batch number(2/17) : Batch loss : 0.05957096070051193\n",
      "Epoch(1/5 : Batch number(3/17) : Batch loss : 0.05481772497296333\n",
      "Epoch(1/5 : Batch number(4/17) : Batch loss : 0.05762002617120743\n",
      "Epoch(1/5 : Batch number(5/17) : Batch loss : 0.03920489922165871\n",
      "Epoch(1/5 : Batch number(6/17) : Batch loss : 0.025745227932929993\n",
      "Epoch(1/5 : Batch number(7/17) : Batch loss : 0.07457751780748367\n",
      "Epoch(1/5 : Batch number(8/17) : Batch loss : 0.14687150716781616\n",
      "Epoch(1/5 : Batch number(9/17) : Batch loss : 0.09572949260473251\n",
      "Epoch(1/5 : Batch number(10/17) : Batch loss : 0.023685762658715248\n",
      "Epoch(1/5 : Batch number(11/17) : Batch loss : 0.08379992097616196\n",
      "Epoch(1/5 : Batch number(12/17) : Batch loss : 0.01921938918530941\n",
      "Epoch(1/5 : Batch number(13/17) : Batch loss : 0.024001561105251312\n",
      "Epoch(1/5 : Batch number(14/17) : Batch loss : 0.032746847718954086\n",
      "Epoch(1/5 : Batch number(15/17) : Batch loss : 0.06174781173467636\n",
      "Epoch(1/5 : Batch number(16/17) : Batch loss : 0.08570104092359543\n",
      "Epoch(1/5 : Batch number(17/17) : Batch loss : 0.10205677896738052\n",
      "Epoch(2/5 : Batch number(1/17) : Batch loss : 0.02174440212547779\n",
      "Epoch(2/5 : Batch number(2/17) : Batch loss : 0.020021384581923485\n",
      "Epoch(2/5 : Batch number(3/17) : Batch loss : 0.035776667296886444\n",
      "Epoch(2/5 : Batch number(4/17) : Batch loss : 0.04847579449415207\n",
      "Epoch(2/5 : Batch number(5/17) : Batch loss : 0.04785900563001633\n",
      "Epoch(2/5 : Batch number(6/17) : Batch loss : 0.014373614452779293\n",
      "Epoch(2/5 : Batch number(7/17) : Batch loss : 0.025699710473418236\n",
      "Epoch(2/5 : Batch number(8/17) : Batch loss : 0.014915930107235909\n",
      "Epoch(2/5 : Batch number(9/17) : Batch loss : 0.07428689301013947\n",
      "Epoch(2/5 : Batch number(10/17) : Batch loss : 0.04581212252378464\n",
      "Epoch(2/5 : Batch number(11/17) : Batch loss : 0.02679073065519333\n",
      "Epoch(2/5 : Batch number(12/17) : Batch loss : 0.014446505345404148\n",
      "Epoch(2/5 : Batch number(13/17) : Batch loss : 0.01776392012834549\n",
      "Epoch(2/5 : Batch number(14/17) : Batch loss : 0.06515666097402573\n",
      "Epoch(2/5 : Batch number(15/17) : Batch loss : 0.009103630669414997\n",
      "Epoch(2/5 : Batch number(16/17) : Batch loss : 0.02180909737944603\n",
      "Epoch(2/5 : Batch number(17/17) : Batch loss : 0.18602554500102997\n",
      "Epoch(3/5 : Batch number(1/17) : Batch loss : 0.03102530911564827\n",
      "Epoch(3/5 : Batch number(2/17) : Batch loss : 0.008780289441347122\n",
      "Epoch(3/5 : Batch number(3/17) : Batch loss : 0.018718751147389412\n",
      "Epoch(3/5 : Batch number(4/17) : Batch loss : 0.009593945927917957\n",
      "Epoch(3/5 : Batch number(5/17) : Batch loss : 0.0031158325728029013\n",
      "Epoch(3/5 : Batch number(6/17) : Batch loss : 0.011288568377494812\n",
      "Epoch(3/5 : Batch number(7/17) : Batch loss : 0.006374372635036707\n",
      "Epoch(3/5 : Batch number(8/17) : Batch loss : 0.004716753959655762\n",
      "Epoch(3/5 : Batch number(9/17) : Batch loss : 0.013541160151362419\n",
      "Epoch(3/5 : Batch number(10/17) : Batch loss : 0.010670451447367668\n",
      "Epoch(3/5 : Batch number(11/17) : Batch loss : 0.006817579735070467\n",
      "Epoch(3/5 : Batch number(12/17) : Batch loss : 0.012698049657046795\n",
      "Epoch(3/5 : Batch number(13/17) : Batch loss : 0.011130377650260925\n",
      "Epoch(3/5 : Batch number(14/17) : Batch loss : 0.020074663683772087\n",
      "Epoch(3/5 : Batch number(15/17) : Batch loss : 0.06970231235027313\n",
      "Epoch(3/5 : Batch number(16/17) : Batch loss : 0.004139569588005543\n",
      "Epoch(3/5 : Batch number(17/17) : Batch loss : 0.0014604678144678473\n",
      "Epoch(4/5 : Batch number(1/17) : Batch loss : 0.00292191538028419\n",
      "Epoch(4/5 : Batch number(2/17) : Batch loss : 0.002636677585542202\n",
      "Epoch(4/5 : Batch number(3/17) : Batch loss : 0.002305779606103897\n",
      "Epoch(4/5 : Batch number(4/17) : Batch loss : 0.004446529317647219\n",
      "Epoch(4/5 : Batch number(5/17) : Batch loss : 0.004227091558277607\n",
      "Epoch(4/5 : Batch number(6/17) : Batch loss : 0.0037167153786867857\n",
      "Epoch(4/5 : Batch number(7/17) : Batch loss : 0.015185863710939884\n",
      "Epoch(4/5 : Batch number(8/17) : Batch loss : 0.005375358741730452\n",
      "Epoch(4/5 : Batch number(9/17) : Batch loss : 0.002483244286850095\n",
      "Epoch(4/5 : Batch number(10/17) : Batch loss : 0.0037391800433397293\n",
      "Epoch(4/5 : Batch number(11/17) : Batch loss : 0.006146034225821495\n",
      "Epoch(4/5 : Batch number(12/17) : Batch loss : 0.0022191584575921297\n",
      "Epoch(4/5 : Batch number(13/17) : Batch loss : 0.002186923986300826\n",
      "Epoch(4/5 : Batch number(14/17) : Batch loss : 0.004489408805966377\n",
      "Epoch(4/5 : Batch number(15/17) : Batch loss : 0.0018496885895729065\n",
      "Epoch(4/5 : Batch number(16/17) : Batch loss : 0.0029758389573544264\n",
      "Epoch(4/5 : Batch number(17/17) : Batch loss : 0.0011384952813386917\n",
      "Training loss : 0.2628690012908705\n"
     ]
    }
   ],
   "source": [
    "# Training the model again from the last CNN Block to The End of the Network\n",
    "dataset = 'C:\\\\Users\\\\Sara Latif Khan\\\\OneDrive\\\\Desktop\\\\FYP_\\\\Scene15\\\\15-Scene'\n",
    "model = model.to(device)\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "#Training Fixed Feature Extractor for 15 epochs\n",
    "num_epochs = 5\n",
    "batch_loss = 0\n",
    "cum_epoch_loss = 0 #cumulative loss for each batch\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cum_epoch_loss = 0\n",
    "  \n",
    "    for batch, (images, labels) in enumerate(trainloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        batch_loss += loss.item()\n",
    "        print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
    "        torch.save(model, dataset+'_model_'+str(e)+'.pt')\n",
    "    \n",
    "print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch (1 / 8)\n",
      "Batch (2 / 8)\n",
      "Batch (3 / 8)\n",
      "Batch (4 / 8)\n",
      "Batch (5 / 8)\n",
      "Batch (6 / 8)\n",
      "Batch (7 / 8)\n",
      "Batch (8 / 8)\n",
      "Accuracy of the model on 450 test images: 86.88888888888889% \n"
     ]
    }
   ],
   "source": [
    "model. to('cpu')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    #set_trace ()\n",
    "    for batch, (images,labels) in enumerate(testloader,1):\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output,1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        num_correct += (pred==labels).sum().item()\n",
    "        print(f'Batch ({batch} / {len(testloader)})')\n",
    "        \n",
    "        # to check the accuracy of model on 5 batches\n",
    "        # if batch == 5:\n",
    "            # break\n",
    "            \n",
    "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total }% ')            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreezing and training over the last two CNN block onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfreezing and training the 2nd last CNN block\n",
    "# For Vgg-16 last block is 3 Convolution layers followed by a Max-Pooling Layer, so when we look at model we are looking \n",
    "# at features from index 24-31, so we are going to train for 5 epochs\n",
    "\n",
    "for i in range(17, 24):\n",
    "    model.features[i].requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(1/17) : Batch loss : 0.0014892679173499346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Sara Latif Khan\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(2/17) : Batch loss : 0.08129754662513733\n",
      "Epoch(0/5 : Batch number(3/17) : Batch loss : 0.0035998360253870487\n",
      "Epoch(0/5 : Batch number(4/17) : Batch loss : 0.008981808088719845\n",
      "Epoch(0/5 : Batch number(5/17) : Batch loss : 0.026876050978899002\n",
      "Epoch(0/5 : Batch number(6/17) : Batch loss : 0.005368266254663467\n",
      "Epoch(0/5 : Batch number(7/17) : Batch loss : 0.03576454147696495\n",
      "Epoch(0/5 : Batch number(8/17) : Batch loss : 0.008622827008366585\n",
      "Epoch(0/5 : Batch number(9/17) : Batch loss : 0.0057098111137747765\n",
      "Epoch(0/5 : Batch number(10/17) : Batch loss : 0.008979284204542637\n",
      "Epoch(0/5 : Batch number(11/17) : Batch loss : 0.05422314256429672\n",
      "Epoch(0/5 : Batch number(12/17) : Batch loss : 0.006226265802979469\n",
      "Epoch(0/5 : Batch number(13/17) : Batch loss : 0.0029522578697651625\n",
      "Epoch(0/5 : Batch number(14/17) : Batch loss : 0.01263727992773056\n",
      "Epoch(0/5 : Batch number(15/17) : Batch loss : 0.0026471749879419804\n",
      "Epoch(0/5 : Batch number(16/17) : Batch loss : 0.013036482036113739\n",
      "Epoch(0/5 : Batch number(17/17) : Batch loss : 0.004557084757834673\n",
      "Epoch(1/5 : Batch number(1/17) : Batch loss : 0.0012861493742093444\n",
      "Epoch(1/5 : Batch number(2/17) : Batch loss : 0.002367127686738968\n",
      "Epoch(1/5 : Batch number(3/17) : Batch loss : 0.004943760111927986\n",
      "Epoch(1/5 : Batch number(4/17) : Batch loss : 0.0046468209475278854\n",
      "Epoch(1/5 : Batch number(5/17) : Batch loss : 0.009351260960102081\n",
      "Epoch(1/5 : Batch number(6/17) : Batch loss : 0.007099124602973461\n",
      "Epoch(1/5 : Batch number(7/17) : Batch loss : 0.002465717028826475\n",
      "Epoch(1/5 : Batch number(8/17) : Batch loss : 0.016387121751904488\n",
      "Epoch(1/5 : Batch number(9/17) : Batch loss : 0.01429357286542654\n",
      "Epoch(1/5 : Batch number(10/17) : Batch loss : 0.015379389747977257\n",
      "Epoch(1/5 : Batch number(11/17) : Batch loss : 0.00421399250626564\n",
      "Epoch(1/5 : Batch number(12/17) : Batch loss : 0.0006271160091273487\n",
      "Epoch(1/5 : Batch number(13/17) : Batch loss : 0.0040008192881941795\n",
      "Epoch(1/5 : Batch number(14/17) : Batch loss : 0.01034997496753931\n",
      "Epoch(1/5 : Batch number(15/17) : Batch loss : 0.00881221890449524\n",
      "Epoch(1/5 : Batch number(16/17) : Batch loss : 0.0017728464445099235\n",
      "Epoch(1/5 : Batch number(17/17) : Batch loss : 0.005108474753797054\n",
      "Epoch(2/5 : Batch number(1/17) : Batch loss : 0.00254126382060349\n",
      "Epoch(2/5 : Batch number(2/17) : Batch loss : 0.0035624385345727205\n",
      "Epoch(2/5 : Batch number(3/17) : Batch loss : 0.001399929984472692\n",
      "Epoch(2/5 : Batch number(4/17) : Batch loss : 0.010947114787995815\n",
      "Epoch(2/5 : Batch number(5/17) : Batch loss : 0.008822445757687092\n",
      "Epoch(2/5 : Batch number(6/17) : Batch loss : 0.0011666588252410293\n",
      "Epoch(2/5 : Batch number(7/17) : Batch loss : 0.0012122050393372774\n",
      "Epoch(2/5 : Batch number(8/17) : Batch loss : 0.005453869234770536\n",
      "Epoch(2/5 : Batch number(9/17) : Batch loss : 0.001243825419805944\n",
      "Epoch(2/5 : Batch number(10/17) : Batch loss : 0.007488505449146032\n",
      "Epoch(2/5 : Batch number(11/17) : Batch loss : 0.00047617501695640385\n",
      "Epoch(2/5 : Batch number(12/17) : Batch loss : 0.021756049245595932\n",
      "Epoch(2/5 : Batch number(13/17) : Batch loss : 0.0007340451702475548\n",
      "Epoch(2/5 : Batch number(14/17) : Batch loss : 0.017790168523788452\n",
      "Epoch(2/5 : Batch number(15/17) : Batch loss : 0.0007427380187436938\n",
      "Epoch(2/5 : Batch number(16/17) : Batch loss : 0.00015175029693637043\n",
      "Epoch(2/5 : Batch number(17/17) : Batch loss : 0.0008128838380798697\n",
      "Epoch(3/5 : Batch number(1/17) : Batch loss : 0.0014853531029075384\n",
      "Epoch(3/5 : Batch number(2/17) : Batch loss : 0.002611542120575905\n",
      "Epoch(3/5 : Batch number(3/17) : Batch loss : 0.0001481955114286393\n",
      "Epoch(3/5 : Batch number(4/17) : Batch loss : 0.00047534226905554533\n",
      "Epoch(3/5 : Batch number(5/17) : Batch loss : 0.0009986927034333348\n",
      "Epoch(3/5 : Batch number(6/17) : Batch loss : 0.003262569662183523\n",
      "Epoch(3/5 : Batch number(7/17) : Batch loss : 0.0007712575024925172\n",
      "Epoch(3/5 : Batch number(8/17) : Batch loss : 0.0011370460269972682\n",
      "Epoch(3/5 : Batch number(9/17) : Batch loss : 0.0004956946359016001\n",
      "Epoch(3/5 : Batch number(10/17) : Batch loss : 0.00043088337406516075\n",
      "Epoch(3/5 : Batch number(11/17) : Batch loss : 0.0008669501403346658\n",
      "Epoch(3/5 : Batch number(12/17) : Batch loss : 0.0007459141779690981\n",
      "Epoch(3/5 : Batch number(13/17) : Batch loss : 0.00041703114402480423\n",
      "Epoch(3/5 : Batch number(14/17) : Batch loss : 0.000360629812348634\n",
      "Epoch(3/5 : Batch number(15/17) : Batch loss : 0.0007507484406232834\n",
      "Epoch(3/5 : Batch number(16/17) : Batch loss : 0.0002530887140892446\n",
      "Epoch(3/5 : Batch number(17/17) : Batch loss : 8.302523929160088e-05\n",
      "Epoch(4/5 : Batch number(1/17) : Batch loss : 0.0006814904627390206\n",
      "Epoch(4/5 : Batch number(2/17) : Batch loss : 0.00013576005585491657\n",
      "Epoch(4/5 : Batch number(3/17) : Batch loss : 0.0007222408312372863\n",
      "Epoch(4/5 : Batch number(4/17) : Batch loss : 0.001428335322998464\n",
      "Epoch(4/5 : Batch number(5/17) : Batch loss : 0.0002586828195489943\n",
      "Epoch(4/5 : Batch number(6/17) : Batch loss : 0.00023258148576132953\n",
      "Epoch(4/5 : Batch number(7/17) : Batch loss : 0.005637073889374733\n",
      "Epoch(4/5 : Batch number(8/17) : Batch loss : 0.00035985116846859455\n",
      "Epoch(4/5 : Batch number(9/17) : Batch loss : 0.00022755198006052524\n",
      "Epoch(4/5 : Batch number(10/17) : Batch loss : 0.00017683992336969823\n",
      "Epoch(4/5 : Batch number(11/17) : Batch loss : 0.0002519058180041611\n",
      "Epoch(4/5 : Batch number(12/17) : Batch loss : 0.00027021332061849535\n",
      "Epoch(4/5 : Batch number(13/17) : Batch loss : 0.00015421716670971364\n",
      "Epoch(4/5 : Batch number(14/17) : Batch loss : 0.00023873989994172007\n",
      "Epoch(4/5 : Batch number(15/17) : Batch loss : 0.0013926525134593248\n",
      "Epoch(4/5 : Batch number(16/17) : Batch loss : 0.0004728207422886044\n",
      "Epoch(4/5 : Batch number(17/17) : Batch loss : 0.0008052022312767804\n",
      "Training loss : 0.030065682750907454\n"
     ]
    }
   ],
   "source": [
    "# Training the model again from the last CNN Block to The End of the Network\n",
    "dataset = 'C:\\\\Users\\\\Sara Latif Khan\\\\OneDrive\\\\Desktop\\\\FYP_\\\\Scene15\\\\15-Scene'\n",
    "model = model.to(device)\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "#Training Fixed Feature Extractor for 15 epochs\n",
    "num_epochs = 5\n",
    "batch_loss = 0\n",
    "cum_epoch_loss = 0 #cumulative loss for each batch\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cum_epoch_loss = 0\n",
    "  \n",
    "    for batch, (images, labels) in enumerate(trainloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        batch_loss += loss.item()\n",
    "        print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
    "        torch.save(model, dataset+'_model_'+str(e)+'.pt')\n",
    "    \n",
    "print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch (1 / 8)\n",
      "Batch (2 / 8)\n",
      "Batch (3 / 8)\n",
      "Batch (4 / 8)\n",
      "Batch (5 / 8)\n",
      "Batch (6 / 8)\n",
      "Batch (7 / 8)\n",
      "Batch (8 / 8)\n",
      "Accuracy of the model on 450 test images: 85.11111111111111% \n"
     ]
    }
   ],
   "source": [
    "model. to('cpu')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    #set_trace ()\n",
    "    for batch, (images,labels) in enumerate(testloader,1):\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output,1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        num_correct += (pred==labels).sum().item()\n",
    "        print(f'Batch ({batch} / {len(testloader)})')\n",
    "        \n",
    "        # to check the accuracy of model on 5 batches\n",
    "        # if batch == 5:\n",
    "            # break\n",
    "            \n",
    "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total }% ')            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  0  0 20  0  0  3  0  0  0  2  0  0  1]\n",
      " [ 0  0  0  1 14  5  0  2  3  0  2  0  1  0  2]\n",
      " [ 0 10  0  0 10  0  0  6  0  0  0  1  1  1  1]\n",
      " [ 0  4  0  2 20  0  0  3  0  0  0  0  0  0  1]\n",
      " [ 0  2  0  1 15  2  0  5  0  0  0  1  0  0  4]\n",
      " [ 0  8  0  0 14  0  1  1  0  0  3  0  2  1  0]\n",
      " [ 0  9  0  0  6  0  0 14  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 12  0  2  8  1  0  1  0  0  0  3  3  0  0]\n",
      " [ 0  2  0  0 25  0  0  2  0  0  1  0  0  0  0]\n",
      " [ 0  5  0  2 10  0  0  7  0  0  5  0  0  1  0]\n",
      " [ 0  8  0  0 12  1  0  0  0  0  0  1  8  0  0]\n",
      " [ 0  9  0  1 11  3  0  4  0  0  0  0  0  0  2]\n",
      " [ 0 11  0  0 16  1  0  2  0  0  0  0  0  0  0]\n",
      " [ 0 18  0  0  6  0  0  4  0  0  0  0  0  0  2]]\n",
      "[ 0.          0.          0.          6.66666667 50.          0.\n",
      "  0.          0.          0.          0.         16.66666667  3.33333333\n",
      "  0.          0.          6.66666667]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb_classes = 15\n",
    "\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "print(conf_mat)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print(class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
